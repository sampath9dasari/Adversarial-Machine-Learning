{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Adversarial 1st.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMErU5vtRsTLzcsae1+zYDl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sampath9dasari/Adversarial-Machine-Learning/blob/master/Adversarial_1st.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YF8U9_CjoXqG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import sklearn as sklearn\n",
        "import pandas as pd\n",
        "from torch import nn, optim\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.nn.functional as F\n",
        "from torchvision import transforms, datasets\n",
        "from multiprocessing import cpu_count\n",
        "from collections import OrderedDict\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "# import olympic"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p171Zj7hpCIF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "if torch.cuda.is_available():\n",
        "    DEVICE = 'cuda'\n",
        "else:\n",
        "    DEVICE = 'cpu'\n",
        "    \n",
        "with plt.style.context('ggplot'):\n",
        "    COLOURS = plt.rcParams['axes.prop_cycle'].by_key()['color']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "boUgaGgGpVjf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sys\n",
        "from typing import Union, Callable, Tuple\n",
        "sys.path.append('../adversarial/')\n",
        "sys.path.append('../')\n",
        "# from functional import boundary, iterated_fgsm, local_search, pgd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZFrpZda9pYVl",
        "colab_type": "code",
        "outputId": "253bd507-d874-46ad-e50c-8f02701f4b23",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 275
        }
      },
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "train = datasets.MNIST('../data/', train=True, transform=transform, download=True)\n",
        "val = datasets.MNIST('../data/', train=False, transform=transform, download=True)\n",
        "\n",
        "train_loader = DataLoader(train, batch_size=128, num_workers=cpu_count())\n",
        "val_loader = DataLoader(val, batch_size=128, num_workers=cpu_count())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 0/9912422 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ../data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "9920512it [00:00, 27610160.02it/s]                            \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ../data/MNIST/raw/train-images-idx3-ubyte.gz to ../data/MNIST/raw\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "32768it [00:00, 450816.10it/s]\n",
            "  1%|          | 16384/1648877 [00:00<00:11, 145254.52it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ../data/MNIST/raw/train-labels-idx1-ubyte.gz\n",
            "Extracting ../data/MNIST/raw/train-labels-idx1-ubyte.gz to ../data/MNIST/raw\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ../data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1654784it [00:00, 7586257.68it/s]                            \n",
            "8192it [00:00, 103931.14it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ../data/MNIST/raw/t10k-images-idx3-ubyte.gz to ../data/MNIST/raw\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ../data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n",
            "Extracting ../data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ../data/MNIST/raw\n",
            "Processing...\n",
            "Done!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bKn9WIIJpf-w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 32, kernel_size=5)\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=5)\n",
        "        self.fc1 = nn.Linear(1024, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
        "        x = F.relu(F.max_pool2d(self.conv2(x), 2))\n",
        "        x = x.view(-1, 1024)\n",
        "        x = self.fc1(x)\n",
        "        return F.log_softmax(x, dim=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4_gRh-G5pirB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "model = Net().to(DEVICE)\n",
        "optimiser = optim.SGD(model.parameters(), lr=0.1)\n",
        "loss_fn = nn.CrossEntropyLoss()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hVYudrb2pk83",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "\n",
        "def projected_gradient_descent(model, x, y, loss_fn, num_steps, step_size, step_norm, eps, eps_norm,\n",
        "                               clamp=(0,1), y_target=None):\n",
        "    \"\"\"Performs the projected gradient descent attack on a batch of images.\"\"\"\n",
        "    x_adv = x.clone().detach().requires_grad_(True).to(x.device)\n",
        "    targeted = y_target is not None\n",
        "    num_channels = x.shape[1]\n",
        "\n",
        "    for i in range(num_steps):\n",
        "        _x_adv = x_adv.clone().detach().requires_grad_(True)\n",
        "\n",
        "        prediction = model(_x_adv)\n",
        "        loss = loss_fn(prediction, y_target if targeted else y)\n",
        "        loss.backward()\n",
        "\n",
        "        with torch.no_grad():\n",
        "            # Force the gradient step to be a fixed size in a certain norm\n",
        "            if step_norm == 'inf':\n",
        "                gradients = _x_adv.grad.sign() * step_size\n",
        "            else:\n",
        "                # Note .view() assumes batched image data as 4D tensor\n",
        "                gradients = _x_adv.grad * step_size / _x_adv.grad.view(_x_adv.shape[0], -1)\\\n",
        "                    .norm(step_norm, dim=-1)\\\n",
        "                    .view(-1, num_channels, 1, 1)\n",
        "\n",
        "            if targeted:\n",
        "                # Targeted: Gradient descent with on the loss of the (incorrect) target label\n",
        "                # w.r.t. the image data\n",
        "                x_adv -= gradients\n",
        "            else:\n",
        "                # Untargeted: Gradient ascent on the loss of the correct label w.r.t.\n",
        "                # the model parameters\n",
        "                x_adv += gradients\n",
        "\n",
        "        # Project back into l_norm ball and correct range\n",
        "        if eps_norm == 'inf':\n",
        "            # Workaround as PyTorch doesn't have elementwise clip\n",
        "            x_adv = torch.max(torch.min(x_adv, x + eps), x - eps)\n",
        "        else:\n",
        "            delta = x_adv - x\n",
        "\n",
        "            # Assume x and x_adv are batched tensors where the first dimension is\n",
        "            # a batch dimension\n",
        "            mask = delta.view(delta.shape[0], -1).norm(norm, dim=1) <= eps\n",
        "\n",
        "            scaling_factor = delta.view(delta.shape[0], -1).norm(norm, dim=1)\n",
        "            scaling_factor[mask] = eps\n",
        "\n",
        "            # .view() assumes batched images as a 4D Tensor\n",
        "            delta *= eps / scaling_factor.view(-1, 1, 1, 1)\n",
        "\n",
        "            x_adv = x + delta\n",
        "            \n",
        "        x_adv = x_adv.clamp(*clamp)\n",
        "\n",
        "    return x_adv.detach()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ye-y0-X8qSoW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}