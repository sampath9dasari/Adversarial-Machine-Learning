{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Homomorphic Encryption.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sampath9dasari/adversarial-machine-learning/blob/master/Homomorphic_Encryption.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t3G_Tg5ONqOK",
        "colab_type": "text"
      },
      "source": [
        "# Privacy Preserving Machine Learning\n",
        "\n",
        "First things first. Let's run the package installations. They take quite a while. So hit run on the cell below before continuing with this introduction.\n",
        "\n",
        "\n",
        "Executing? Perfect!  \n",
        "\n",
        "Consider the following scenario: You are business that speaclizes in machine learning. You have trained some great models on data that has been carefully collected and labeled. The data is quite sensitve and you had to jump through a lot of legal and hoops to get access to it. In this notebook this data will be represented by the android permission data that we have been working so far. Since that you are working on is sensitve and hard to get you are faced with a porblem. Your clients are reclutant to give you their data but at the same time you don't want to give your model to them either. \n",
        "But there are solutions to this problem and it this notebook we will explore to of those. Namely Secure Multiparty Computation SMC (also often called just Multi Party Computation  MPC) and Homomorphic Encryption(HE). Both are cryptographic ways of performing computation on data that is being kept secret. Here we will be focusing on HE\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lzxJKgI0ttbm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "409f2a48-ebbd-4ed0-cbfd-f1511517c5c9"
      },
      "source": [
        "!pip install Pyfhel"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: Pyfhel in /usr/local/lib/python3.6/dist-packages (2.0.1)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.6/dist-packages (from Pyfhel) (1.18.2)\n",
            "Requirement already satisfied: cython>=0.25.1 in /usr/local/lib/python3.6/dist-packages (from Pyfhel) (0.29.16)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3K1fejzQOHlv",
        "colab_type": "text"
      },
      "source": [
        "Next we'll get our usual boilerplat code out of the way. Data loading, splitting, etc."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qC4Gopq83IVf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "33ebe385-5bb0-4f31-9c35-2d232a735802"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "\n",
        "# select a subset of the data\n",
        "# we only wants ones and zeros\n",
        "# 200 instances per class\n",
        "\n",
        "# instances\n",
        "x_train = np.concatenate( [ x_train[ y_train == 0 ][ :200 ], x_train[ y_train == 1 ][ :200 ] ] )\n",
        "x_test = np.concatenate( [ x_test[ y_test == 0 ][ :200 ], x_test[ y_test == 1 ][ :200 ] ] )\n",
        "# x_train = x_train.astype( float ) / 255.\n",
        "# x_test = x_test.astype( float ) / 255.\n",
        "\n",
        "\n",
        "x_train_rounded = np.round( x_train )\n",
        "\n",
        "print( 'training data: ', x_train.shape )\n",
        "print( 'test data: ', x_test.shape )\n",
        "\n",
        "# labels\n",
        "y_train = np.concatenate( [ np.zeros( 200 ), np.ones( 200 ) ] )\n",
        "y_test = np.concatenate( [ np.zeros( 200 ), np.ones( 200 ) ] )\n",
        "\n",
        "print( 'training data: ', y_train.shape )\n",
        "print( 'test data: ', y_test.shape )\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "training data:  (400, 28, 28)\n",
            "test data:  (400, 28, 28)\n",
            "training data:  (400,)\n",
            "test data:  (400,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MbZc1nu0YvnO",
        "colab_type": "text"
      },
      "source": [
        "## Fully Homomorphic encryption\n",
        "\n",
        "Fully Homomorphic encryption is a tool that can be used for PPML. It does not rely on splitting the secret between parties to jointly evaluate a function. It is more like \"traditional\" cryptography in the sense that the one party encrypts the data. Any other party can perform computation the data without the need for decrypting it. The result of the computation is still encrypted. \n",
        "\n",
        "Opposed to whwat we have been doing so far we will not be working with a high level library but rather will build our own functions on top of simple operations.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bEqLf7XU0hwe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from Pyfhel import Pyfhel, PyPtxt, PyCtxt\n",
        "import time\n",
        "\n",
        "# Pyfhel class contains most of the functions.\n",
        "# PyPtxt is the plaintext class\n",
        "# PyCtxt is the ciphertext class\n",
        "\n",
        "\n",
        "HE = Pyfhel()           \n",
        "# p (long): Plaintext modulus. All operations are modulo p.\n",
        "# m (long=2048): Coefficient modulus.\n",
        "# flagBatching (bool=false): Set to true to enable batching.\n",
        "# base (long=2): Polynomial base.\n",
        "# sec (long=128): Security level equivalent in AES. 128 or 192.\n",
        "# intDigits (int=64): truncated positions for integer part.\n",
        "# fracDigits (int=32): truncated positions for fractional part.\n",
        "HE.contextGen(p=65537)  \n",
        "\n",
        "# generate keys\n",
        "HE.keyGen()           \n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "foLSTuXF6Jyt",
        "colab_type": "text"
      },
      "source": [
        "Before we can encrypt nmumber we need to encode them. After that we can perform computation on the ciphertexts. Once we decrypt the result we need to decode it into the desired format."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Jp5FXlQ6Kcu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "472b98a7-d55a-42c0-9a54-92f4542b01b5"
      },
      "source": [
        "# plaintext values\n",
        "a = 1\n",
        "b = 2\n",
        "\n",
        "# encode\n",
        "a = HE.encodeInt( a )\n",
        "print('a:', a.to_string() )\n",
        "b = HE.encodeInt( b )\n",
        "print('b:', b.to_string() )\n",
        "\n",
        "# encrypt\n",
        "a_ctxt = HE.encrypt( a )\n",
        "b_ctxt = HE.encrypt( b )\n",
        "\n",
        "# perform computation\n",
        "result = a_ctxt + b_ctxt\n",
        "decrypted = HE.decrypt( result )\n",
        "\n",
        "# decrypt\n",
        "print( 'decrypted:', decrypted.to_string() ) \n",
        "\n",
        "# decdode\n",
        "print( 'decoded:', HE.decodeInt( decrypted ) )\n",
        "\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "a: b'1'\n",
            "b: b'1x^1'\n",
            "decrypted: b'1x^1 + 1'\n",
            "decoded: 3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L26LQDtx-Xt-",
        "colab_type": "text"
      },
      "source": [
        "Thankfully we don't have to encode and decode evertime. There are convience methods for it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tRwzN-mL-XXI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8ca2fcb5-b771-4081-f132-f9429d15a3b2"
      },
      "source": [
        "# plaintext values\n",
        "a = 1\n",
        "b = 2\n",
        "\n",
        "# encpde and encrypt\n",
        "a_ctxt = HE.encryptInt( a )\n",
        "b_ctxt = HE.encryptInt( b )\n",
        "\n",
        "# perform computation\n",
        "result = a_ctxt + b_ctxt\n",
        "\n",
        "# decrypt and decdode\n",
        "print( 'decerypted and decoded:', HE.decryptInt( result ) )"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "decerypted and decoded: 3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hjr4YTnB_fZC",
        "colab_type": "text"
      },
      "source": [
        "Using the functions `encodeFrac`, `decodeFrac` and `encryptFrac` and `decryptFrac` to replicate the firs example with float values. What do you notice about the encoding?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nNITITH8_1oE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "e00a3f88-d3b9-46ff-ac73-8a35f4c24fec"
      },
      "source": [
        "# plaintext values\n",
        "a = .1\n",
        "b = .2\n",
        "\n",
        "# encode\n",
        "a = HE.encodeFrac( a )\n",
        "print('a:', a.to_string() )\n",
        "b = HE.encodeFrac( b )\n",
        "print('b:', b.to_string() )\n",
        "\n",
        "# encrypt\n",
        "a_ctxt = HE.encrypt(a)\n",
        "b_ctxt = HE.encrypt(b)\n",
        "\n",
        "# perform computation\n",
        "result = a_ctxt + b_ctxt\n",
        "decrypted = HE.decrypt( result )\n",
        "\n",
        "# decrypt\n",
        "print( 'decrypted:', decrypted.to_string() ) \n",
        "\n",
        "# decdode\n",
        "print( 'decoded:',  HE.decodeFrac( decrypted ))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "a: b'10000x^2044 + 10000x^2043 + 10000x^2040 + 10000x^2039 + 10000x^2036 + 10000x^2035 + 10000x^2032 + 10000x^2031 + 10000x^2028 + 10000x^2027 + 10000x^2024 + 10000x^2023 + 10000x^2020 + 10000x^2019 + 10000x^2016'\n",
            "b: b'10000x^2045 + 10000x^2044 + 10000x^2041 + 10000x^2040 + 10000x^2037 + 10000x^2036 + 10000x^2033 + 10000x^2032 + 10000x^2029 + 10000x^2028 + 10000x^2025 + 10000x^2024 + 10000x^2021 + 10000x^2020 + 10000x^2017 + 10000x^2016'\n",
            "decrypted: b'10000x^2045 + FFFFx^2044 + 10000x^2043 + 10000x^2041 + FFFFx^2040 + 10000x^2039 + 10000x^2037 + FFFFx^2036 + 10000x^2035 + 10000x^2033 + FFFFx^2032 + 10000x^2031 + 10000x^2029 + FFFFx^2028 + 10000x^2027 + 10000x^2025 + FFFFx^2024 + 10000x^2023 + 10000x^2021 + FFFFx^2020 + 10000x^2019 + 10000x^2017 + FFFFx^2016'\n",
            "decoded: 0.2999999998137355\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wGM0vYOOKqz3",
        "colab_type": "text"
      },
      "source": [
        "But what about the noise? I thought there was noise involved int HE?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N1uN0CUAEPMo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ab6af674-7344-4ca6-ada4-89d421965b57"
      },
      "source": [
        "HE = Pyfhel()           \n",
        "HE.contextGen( p=65537 )  \n",
        "# generate keys\n",
        "HE.keyGen()      \n",
        "\n",
        "# plaintext values\n",
        "a = 1\n",
        "b = 2\n",
        "\n",
        "# encpde and encrypt\n",
        "a_ctxt = HE.encryptInt( a )\n",
        "b_ctxt = HE.encryptInt( b )\n",
        "\n",
        "# perform computation\n",
        "result = a_ctxt * b_ctxt\n",
        "result = result * a_ctxt\n",
        "\n",
        "print( 'decerypted and decoded:', HE.decryptInt( result ) )\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "decerypted and decoded: -4734767386158461553\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jBLMwgmXLMIJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d9a46757-94fb-4bc5-c6fd-e75cc49f9cf8"
      },
      "source": [
        "HE = Pyfhel()           \n",
        "# p (long): Plaintext modulus. All operations are modulo p.\n",
        "# m (long=2048): Coefficient modulus.\n",
        "# flagBatching (bool=false): Set to true to enable batching.\n",
        "# base (long=2): Polynomial base.\n",
        "# sec (long=128): Security level equivalent in AES. 128 or 192.\n",
        "# intDigits (int=64): truncated positions for integer part.\n",
        "# fracDigits (int=32): truncated positions for fractional part.\n",
        "HE.contextGen( p=65537, m=4096 )  \n",
        "\n",
        "# generate keys\n",
        "HE.keyGen()      \n",
        "\n",
        "# plaintext values\n",
        "a = 1\n",
        "b = 2\n",
        "\n",
        "# encpde and encrypt\n",
        "a_ctxt = HE.encryptInt( a )\n",
        "b_ctxt = HE.encryptInt( b )\n",
        "\n",
        "# perform computation\n",
        "result = a_ctxt * b_ctxt\n",
        "result = result * a_ctxt\n",
        "\n",
        "print( 'decerypted and decoded:', HE.decryptInt( result ) )"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "decerypted and decoded: 2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p1ztfvsB0iOI",
        "colab_type": "text"
      },
      "source": [
        "For a simple example consider the following scenario. We are still working with the MNIST data set (that we all know and love) but to keep things simple we are only using two classes and small amount of data. First we are training a simple classifier on plain data. Namely a perceptron. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JOmdQj2u2L7n",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "da31c76c-fd07-42bb-b0da-d1fad54c417f"
      },
      "source": [
        "from sklearn.linear_model import Perceptron\n",
        "\n",
        "percp = Perceptron(fit_intercept=False)\n",
        "percp.fit( x_train.reshape( ( x_train.shape[ 0 ], -1 ) ), y_train )\n",
        "print( 'test score: ', percp.score( x_test.reshape( ( x_train.shape[ 0 ], -1 ) ), y_test ) )\n",
        "\n",
        "\n",
        "print( 'prediction:', percp.predict( x_test[ 1:2 ].reshape( ( 1, -1 ) ) ) )\n",
        "print( 'output:', percp.decision_function( x_test[ 1:2 ].reshape( ( 1, -1 ) ) ) )\n",
        "print( 'actual lable:', y_test[ 1:2 ] )"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "test score:  1.0\n",
            "prediction: [0.]\n",
            "output: [-3543691.]\n",
            "actual lable: [0.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lktVcb107ayr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e3471dbc-ce51-4483-8c47-4f8dc9af825c"
      },
      "source": [
        "percp.coef_[0].shape"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(784,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DWAJIsxcxhIh",
        "colab_type": "text"
      },
      "source": [
        "Let's transfere the the perceptron algorithm to the encrypted domain. We can perform operations between plaintexts and ciphertexts but we need to encode the plaintexts first"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8kg6SNgiNPTw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "d29baa93-b2ae-4208-bc9d-bf77c7ff0390"
      },
      "source": [
        "from Pyfhel import Pyfhel, PyPtxt, PyCtxt\n",
        "import time\n",
        "\n",
        "# Pyfhel class contains most of the functions.\n",
        "# PyPtxt is the plaintext class\n",
        "# PyCtxt is the ciphertext class\n",
        "\n",
        "\n",
        "HE = Pyfhel()           \n",
        "# p (long): Plaintext modulus. All operations are modulo p.\n",
        "# m (long=2048): Coefficient modulus.\n",
        "# flagBatching (bool=false): Set to true to enable batching.\n",
        "# base (long=2): Polynomial base.\n",
        "# sec (long=128): Security level equivalent in AES. 128 or 192.\n",
        "# intDigits (int=64): truncated positions for integer part.\n",
        "# fracDigits (int=32): truncated positions for fractional part.\n",
        "HE.contextGen(p=65537, m=4096)  \n",
        "\n",
        "# generate keys\n",
        "HE.keyGen()           \n",
        "\n",
        "# encrypt values\n",
        "x_ctxt = [HE.encrypt(x) for x in x_test[1].reshape(-1)]\n",
        "prediction = HE.encrypt(0)\n",
        "\n",
        "# encode weights\n",
        "weights = [HE.encryptInt(x) for x in percp.coef_[0].reshape(-1)]\n",
        "\n",
        "start = time.time()\n",
        "\n",
        "# perform prediction\n",
        "for w, x in zip(weights, x_ctxt):\n",
        "  temp = w*x\n",
        "  prediction = prediction + temp\n",
        "\n",
        "# decrypt results\n",
        "print( 'prediction took:', time.time() - start )\n",
        "result = HE.decryptInt( prediction )\n",
        "print( 'prediction:', result )\n",
        "print( 'actual label:', y_test[ 1 ] )\n"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "prediction took: 5.019931793212891\n",
            "prediction: -3543691\n",
            "actual label: 0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OyC_UI8nrlfY",
        "colab_type": "text"
      },
      "source": [
        "let's do it with SIMD"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZACRcz2IURuo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "outputId": "ced1e4a7-7176-4778-c46d-0f65894c361c"
      },
      "source": [
        "HE = Pyfhel()           \n",
        "HE.contextGen( p=65537, flagBatching=True, )   \n",
        "\n",
        "# generate keys\n",
        "HE.keyGen()    \n",
        "\n",
        "# plain data\n",
        "a = [ 1,2,3,4 ]\n",
        "b = 2\n",
        "\n",
        "a = HE.encodeBatch( a )\n",
        "print( 'encoded:', a.to_string() )\n",
        "\n",
        "a = HE.encrypt( a )\n",
        "\n",
        "# adding another value\n",
        "try:\n",
        "  print( 'try 1')\n",
        "  b_enc = HE.encodeInt( b )\n",
        "  a = a + b_enc\n",
        "  print( 'success!!')\n",
        "except Exception as e:\n",
        "  print( e )\n",
        "\n",
        "try:\n",
        "  print( 'try 2')\n",
        "  b_enc = HE.encodeBatch( b )\n",
        "  a = a + b_enc\n",
        "  print( 'success!!')\n",
        "except Exception as e:\n",
        "  print( e )\n",
        "\n",
        "try:\n",
        "  print( 'try 3')\n",
        "  b_enc = HE.encodeBatch( [b] * 4 )\n",
        "  a = a + b_enc\n",
        "  print( 'success!!')\n",
        "except Exception as e:\n",
        "  print( e )\n",
        "\n",
        "print( 'decoded and decrypted: ', HE.decryptBatch( a ) )\n"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "encoded: b'2E20x^2047 + 69FBx^2046 + A71Ax^2045 + 93E3x^2044 + 8D57x^2043 + AF8Ax^2042 + AD31x^2041 + 7E99x^2040 + 5F6Dx^2039 + AC6x^2038 + AC38x^2037 + 3A71x^2036 + 7EF1x^2035 + 86D2x^2034 + 7C24x^2033 + C543x^2032 + 3548x^2031 + 51CAx^2030 + 4DA0x^2029 + 548Ex^2028 + E4F0x^2027 + 5419x^2026 + 6E48x^2025 + 911Ex^2024 + 4D17x^2023 + C36Ax^2022 + EA40x^2021 + A04Cx^2020 + AD3Dx^2019 + C605x^2018 + CE37x^2017 + 6BC9x^2016 + 2D6Ax^2015 + 2A4Dx^2014 + 4798x^2013 + D1E6x^2012 + D72Fx^2011 + 7B7Cx^2010 + CA8Dx^2009 + FF75x^2008 + E389x^2007 + EF2x^2006 + 2D29x^2005 + 5E22x^2004 + 1BD3x^2003 + 843Dx^2002 + F779x^2001 + C66Cx^2000 + 5E74x^1999 + 6DAEx^1998 + 9949x^1997 + 2301x^1996 + 517Ex^1995 + 8DC0x^1994 + BD10x^1993 + 8B41x^1992 + 7FCCx^1991 + 6378x^1990 + 25E8x^1989 + 96DBx^1988 + C265x^1987 + 41Cx^1986 + BBA7x^1985 + BB74x^1984 + 2AFAx^1983 + CF09x^1982 + A6x^1981 + 91D7x^1980 + 4657x^1979 + 4699x^1978 + C8A8x^1977 + D0B5x^1976 + D155x^1975 + 9CECx^1974 + 4F7Cx^1973 + 64EDx^1972 + E85Ex^1971 + D433x^1970 + BBAFx^1969 + 24D5x^1968 + D9FFx^1967 + 9666x^1966 + 66C4x^1965 + E908x^1964 + E25Bx^1963 + FF32x^1962 + D834x^1961 + 8004x^1960 + 33C1x^1959 + 5FD1x^1958 + 771Bx^1957 + 342Cx^1956 + 8ED3x^1955 + BC01x^1954 + 118Ax^1953 + 9B85x^1952 + E97Bx^1951 + C43x^1950 + ECECx^1949 + BA5Bx^1948 + AF1Cx^1947 + B1ABx^1946 + 11C5x^1945 + 4715x^1944 + 1210x^1943 + DAE5x^1942 + AB44x^1941 + 72BAx^1940 + 844Ax^1939 + 91D6x^1938 + FD2Bx^1937 + 74C2x^1936 + F6FCx^1935 + 5A01x^1934 + E300x^1933 + 1148x^1932 + A581x^1931 + 2DE7x^1930 + 4B95x^1929 + 30F2x^1928 + 3171x^1927 + 17BFx^1926 + C55Dx^1925 + 3B58x^1924 + 506Fx^1923 + 5ABEx^1922 + DE7Dx^1921 + EBC5x^1920 + FACBx^1919 + 5176x^1918 + 4B5Ax^1917 + 961Ax^1916 + B7C5x^1915 + 1EADx^1914 + B975x^1913 + 3BB9x^1912 + 70E7x^1911 + FDA2x^1910 + 5A5Ax^1909 + A74Cx^1908 + DD15x^1907 + EB42x^1906 + 1D21x^1905 + 47B8x^1904 + CC47x^1903 + 9BE8x^1902 + 8804x^1901 + 997Bx^1900 + A334x^1899 + 5CE1x^1898 + D2DFx^1897 + A721x^1896 + 9033x^1895 + E159x^1894 + FF1Fx^1893 + 93EFx^1892 + 3A0Bx^1891 + 98ABx^1890 + 2DFBx^1889 + 1784x^1888 + 7068x^1887 + FFD3x^1886 + 97BBx^1885 + 925Cx^1884 + 1597x^1883 + F53Dx^1882 + 4B66x^1881 + 2356x^1880 + DA2Cx^1879 + D3D7x^1878 + 7958x^1877 + 7DFAx^1876 + 5853x^1875 + DFCAx^1874 + ABBx^1873 + 3B8Bx^1872 + BD0x^1871 + 1A49x^1870 + 2055x^1869 + 23EBx^1868 + AFFBx^1867 + 1463x^1866 + 514Bx^1865 + 1805x^1864 + A681x^1863 + 5AF7x^1862 + C53Fx^1861 + CFC6x^1860 + 6E5Fx^1859 + 658Ax^1858 + E1BCx^1857 + 20FFx^1856 + 5E23x^1855 + 74CBx^1854 + EBE1x^1853 + 7F58x^1852 + C1E9x^1851 + 7327x^1850 + BAEAx^1849 + 7DC2x^1848 + C89Cx^1847 + 4E3Cx^1846 + 4AC6x^1845 + 54F4x^1844 + FFE4x^1843 + C66Cx^1842 + ADB1x^1841 + 7CFAx^1840 + 985Cx^1839 + D9Cx^1838 + CDC2x^1837 + 7347x^1836 + B116x^1835 + 6D0Ex^1834 + 1B6Bx^1833 + 2580x^1832 + B994x^1831 + 8547x^1830 + B554x^1829 + 910Fx^1828 + 9017x^1827 + D240x^1826 + C1B3x^1825 + 7E0Ax^1824 + 1F0Dx^1823 + F586x^1822 + EB79x^1821 + F682x^1820 + D3F5x^1819 + 89Cx^1818 + B2F7x^1817 + A418x^1816 + 9354x^1815 + 8B8Cx^1814 + 603Cx^1813 + 5D9Dx^1812 + F47Fx^1811 + D5FFx^1810 + 7926x^1809 + 90F5x^1808 + AE3Ex^1807 + 6D16x^1806 + E22Cx^1805 + 359Fx^1804 + 1F7Cx^1803 + A83Dx^1802 + F4A5x^1801 + 8CD9x^1800 + D2AAx^1799 + 775Fx^1798 + 19FEx^1797 + 35D5x^1796 + E558x^1795 + BA8Ax^1794 + 828Ex^1793 + Fx^1792 + 34E0x^1791 + 8CD9x^1790 + FE94x^1789 + 1787x^1788 + 779Ex^1787 + FE68x^1786 + 83D6x^1785 + 38C4x^1784 + 3200x^1783 + 4F1Cx^1782 + E64Dx^1781 + 6DDx^1780 + 4FA3x^1779 + 7DF0x^1778 + B9Ax^1777 + FBA4x^1776 + 17F2x^1775 + 6E85x^1774 + 89CBx^1773 + EC88x^1772 + 3DD2x^1771 + 2557x^1770 + B83Dx^1769 + 9FC2x^1768 + AE7Cx^1767 + E8F1x^1766 + D9BCx^1765 + D024x^1764 + AE0Bx^1763 + D796x^1762 + 7627x^1761 + 2413x^1760 + B7BCx^1759 + A832x^1758 + C357x^1757 + 4DB9x^1756 + A5A5x^1755 + 892Dx^1754 + A803x^1753 + 62F3x^1752 + 812Dx^1751 + 5F11x^1750 + 5F3Bx^1749 + 1560x^1748 + D960x^1747 + 75EEx^1746 + 40E3x^1745 + F303x^1744 + 96F9x^1743 + 95E6x^1742 + FC22x^1741 + 5B21x^1740 + 347Cx^1739 + BAA7x^1738 + D1B3x^1737 + CD39x^1736 + FD75x^1735 + 3B6Bx^1734 + 8E35x^1733 + B632x^1732 + 38C7x^1731 + CC53x^1730 + 24Cx^1729 + 5AA5x^1728 + 3C60x^1727 + 9B44x^1726 + 379Cx^1725 + 9D6Dx^1724 + 9B67x^1723 + F2F8x^1722 + 2FC7x^1721 + 33E1x^1720 + 1C4x^1719 + 74C8x^1718 + 9143x^1717 + FAC7x^1716 + E7EAx^1715 + A122x^1714 + 23A8x^1713 + 1A39x^1712 + B28Ax^1711 + 8E73x^1710 + A277x^1709 + EBB8x^1708 + A591x^1707 + 3E34x^1706 + BC0Bx^1705 + F1EFx^1704 + 3037x^1703 + 2F60x^1702 + 60FBx^1701 + 84Ax^1700 + AEC9x^1699 + 9068x^1698 + F59Ex^1697 + A721x^1696 + 6329x^1695 + 84C5x^1694 + 2612x^1693 + C22x^1692 + 17AAx^1691 + 649x^1690 + 8787x^1689 + E5EEx^1688 + E5AAx^1687 + 4233x^1686 + 3201x^1685 + 3EE4x^1684 + 46B9x^1683 + DDAx^1682 + 30F1x^1681 + 38x^1680 + 3281x^1679 + 671Fx^1678 + 3BE7x^1677 + 7FABx^1676 + 2A95x^1675 + 6DD3x^1674 + 5006x^1673 + C6D8x^1672 + 2FC9x^1671 + C4EBx^1670 + 4F01x^1669 + AB14x^1668 + 9976x^1667 + 4E08x^1666 + BA37x^1665 + F7C1x^1664 + EE77x^1663 + E211x^1662 + 216Ax^1661 + 6D09x^1660 + 2DACx^1659 + 4CCAx^1658 + 3A57x^1657 + 156x^1656 + D0A1x^1655 + 6EE9x^1654 + D431x^1653 + 813Fx^1652 + E92x^1651 + 5C2Dx^1650 + 3A37x^1649 + 15D8x^1648 + D95Bx^1647 + D3ACx^1646 + CE76x^1645 + 87D2x^1644 + F9C7x^1643 + F316x^1642 + 555Cx^1641 + 437x^1640 + 505Ex^1639 + B61Bx^1638 + E3C1x^1637 + D38x^1636 + 5C52x^1635 + 7C46x^1634 + 275Ax^1633 + 4B0Bx^1632 + 7E32x^1631 + 27E9x^1630 + BE6Dx^1629 + 402Bx^1628 + C715x^1627 + 1E41x^1626 + 5E21x^1625 + 20D5x^1624 + A0FDx^1623 + 395Bx^1622 + 91B9x^1621 + 5F02x^1620 + BA36x^1619 + EDDBx^1618 + FB42x^1617 + 99AFx^1616 + B27Bx^1615 + 760Bx^1614 + A3C1x^1613 + CE2Bx^1612 + 2D1Ax^1611 + 8B36x^1610 + 9936x^1609 + 8BCx^1608 + B252x^1607 + 427Fx^1606 + 4CF4x^1605 + D6AEx^1604 + 3FDDx^1603 + C62Dx^1602 + B36Bx^1601 + AFB1x^1600 + C3DDx^1599 + BA9Cx^1598 + 765x^1597 + FA02x^1596 + CDFDx^1595 + 5418x^1594 + BB9x^1593 + D015x^1592 + 3A0Dx^1591 + EA9x^1590 + CC64x^1589 + 8F80x^1588 + 81FBx^1587 + 522Ax^1586 + 5367x^1585 + A2EBx^1584 + 250Dx^1583 + A7F3x^1582 + 1C81x^1581 + 4888x^1580 + 8EDBx^1579 + 7825x^1578 + 6D60x^1577 + 764Fx^1576 + A28Dx^1575 + 74ADx^1574 + EC4Dx^1573 + C0FEx^1572 + 7F93x^1571 + 7112x^1570 + AD90x^1569 + 55C0x^1568 + 56BEx^1567 + 9E7Fx^1566 + 57Ex^1565 + 30C5x^1564 + 80C8x^1563 + A38Cx^1562 + 8102x^1561 + BAB9x^1560 + C8DBx^1559 + D8E4x^1558 + 755Cx^1557 + C1B1x^1556 + 2496x^1555 + 9357x^1554 + ABE7x^1553 + 4566x^1552 + D250x^1551 + EC9Cx^1550 + 29D0x^1549 + 2272x^1548 + BE05x^1547 + DA15x^1546 + 5D04x^1545 + 2FE4x^1544 + D806x^1543 + A66Bx^1542 + 3039x^1541 + E117x^1540 + D4DFx^1539 + 6CB4x^1538 + 46Ex^1537 + F80Dx^1536 + E7DFx^1535 + 2702x^1534 + 2416x^1533 + 3F95x^1532 + E22x^1531 + 4D1Ax^1530 + 19Ex^1529 + E626x^1528 + 6DDBx^1527 + 712Dx^1526 + 1C52x^1525 + 4019x^1524 + C7B8x^1523 + AF8Ex^1522 + 648Ex^1521 + 1E50x^1520 + 15BCx^1519 + 8FE2x^1518 + CB5Cx^1517 + 4520x^1516 + FEDBx^1515 + D528x^1514 + 53D6x^1513 + 2204x^1512 + EE7Fx^1511 + BFA4x^1510 + 73E0x^1509 + 83DDx^1508 + E5E3x^1507 + B48Cx^1506 + 10BDx^1505 + A928x^1504 + DBFx^1503 + 50DFx^1502 + CF6x^1501 + B778x^1500 + 7F86x^1499 + 5E37x^1498 + EA8Cx^1497 + FCEEx^1496 + B286x^1495 + 343Ax^1494 + DC56x^1493 + A58Ax^1492 + C3CBx^1491 + B89Dx^1490 + 339Cx^1489 + D351x^1488 + 673Ex^1487 + 410Bx^1486 + BCA6x^1485 + A13x^1484 + E40Fx^1483 + A4C4x^1482 + AE0Dx^1481 + C76Fx^1480 + 17EFx^1479 + AE90x^1478 + B55Ex^1477 + 72F9x^1476 + 42B5x^1475 + 867x^1474 + 4900x^1473 + C8C8x^1472 + B146x^1471 + DE24x^1470 + 672Fx^1469 + B143x^1468 + 1FF5x^1467 + 2E54x^1466 + 7029x^1465 + 631x^1464 + C8A3x^1463 + BF45x^1462 + 801x^1461 + 7DABx^1460 + 88C7x^1459 + 208Fx^1458 + BC6Ax^1457 + D15x^1456 + 8A67x^1455 + 71F9x^1454 + 6271x^1453 + E007x^1452 + 5C73x^1451 + 94BBx^1450 + 5469x^1449 + ED54x^1448 + F302x^1447 + 3FF9x^1446 + 60C9x^1445 + FF68x^1444 + 99C3x^1443 + 48C2x^1442 + 4CCBx^1441 + E04Dx^1440 + 3420x^1439 + E5F5x^1438 + 3E69x^1437 + 421Cx^1436 + C672x^1435 + 3D4Cx^1434 + 52CDx^1433 + F84x^1432 + 8FA5x^1431 + 3034x^1430 + AD5Dx^1429 + C12Dx^1428 + EDDAx^1427 + 5934x^1426 + 9555x^1425 + 76BEx^1424 + 43A6x^1423 + FC1Fx^1422 + 2687x^1421 + 86F1x^1420 + 7E08x^1419 + C9B5x^1418 + 3A5Dx^1417 + F050x^1416 + AB0Bx^1415 + D49x^1414 + 4FA1x^1413 + BC8Ax^1412 + E456x^1411 + 7404x^1410 + 4997x^1409 + 3DBDx^1408 + 7F26x^1407 + 3081x^1406 + 728x^1405 + 385Ex^1404 + BC6Bx^1403 + A0A9x^1402 + 1395x^1401 + 9E2Fx^1400 + B295x^1399 + 8BEFx^1398 + 14A3x^1397 + 1D91x^1396 + 5DB0x^1395 + 827Bx^1394 + F5F1x^1393 + 8485x^1392 + B59Dx^1391 + 9C90x^1390 + DF1Cx^1389 + 1BF2x^1388 + 38F0x^1387 + 9AF2x^1386 + 8C77x^1385 + 4081x^1384 + 527Bx^1383 + 7D45x^1382 + B8FCx^1381 + 2587x^1380 + E0EBx^1379 + F054x^1378 + BB8Ex^1377 + 8A00x^1376 + FECEx^1375 + D8A4x^1374 + 76B9x^1373 + B38Ax^1372 + 6454x^1371 + ECD9x^1370 + 8FB7x^1369 + 15D8x^1368 + 4E72x^1367 + CDF8x^1366 + 1321x^1365 + D86Ex^1364 + 3BBBx^1363 + 792Ex^1362 + D7EBx^1361 + 69C1x^1360 + D552x^1359 + A511x^1358 + 8E3Ax^1357 + 52F3x^1356 + 94EBx^1355 + C80Bx^1354 + 9B2Fx^1353 + 6D0Dx^1352 + B26Fx^1351 + DD71x^1350 + 7867x^1349 + 8F07x^1348 + 66EDx^1347 + C58Ex^1346 + 6465x^1345 + B213x^1344 + 7EC3x^1343 + F16x^1342 + D1E8x^1341 + 1FDEx^1340 + 33Dx^1339 + 916Ax^1338 + 5EFEx^1337 + 8305x^1336 + 7579x^1335 + FD2Cx^1334 + CF22x^1333 + 341Cx^1332 + DE17x^1331 + F423x^1330 + 2C36x^1329 + 37Dx^1328 + 5B80x^1327 + 435Fx^1326 + 2280x^1325 + A0D4x^1324 + 69D2x^1323 + DB5Ex^1322 + 7299x^1321 + 44DDx^1320 + 3F9Fx^1319 + F720x^1318 + 8816x^1317 + 9518x^1316 + 100x^1315 + 577x^1314 + 8CB8x^1313 + 3B9x^1312 + 679Cx^1311 + 36E9x^1310 + F30Cx^1309 + 549Bx^1308 + 8454x^1307 + AC9Bx^1306 + EDAAx^1305 + 419Ax^1304 + 92F1x^1303 + CBCx^1302 + 10B8x^1301 + 1D6Ax^1300 + 8EF6x^1299 + A3A6x^1298 + 20EDx^1297 + 26F7x^1296 + 2BDDx^1295 + 7D1Fx^1294 + E2A6x^1293 + 196Cx^1292 + D5F1x^1291 + 8BF8x^1290 + 3107x^1289 + A823x^1288 + 85ACx^1287 + B50Dx^1286 + 7E29x^1285 + C05Fx^1284 + 5D45x^1283 + 2FEx^1282 + 61D7x^1281 + 11x^1280 + 4269x^1279 + 75E1x^1278 + EBF3x^1277 + 5184x^1276 + B026x^1275 + 2CECx^1274 + D7C7x^1273 + FE48x^1272 + D7BFx^1271 + F901x^1270 + 2DB5x^1269 + DC91x^1268 + C5A2x^1267 + 96A5x^1266 + B1D0x^1265 + A8EDx^1264 + B5FAx^1263 + 484Dx^1262 + B4C9x^1261 + 1300x^1260 + 671Bx^1259 + 4BCFx^1258 + DEBBx^1257 + F0CEx^1256 + 2255x^1255 + B6A3x^1254 + ACFCx^1253 + 702Bx^1252 + 297Fx^1251 + 98B4x^1250 + 2AC5x^1249 + 328Ex^1248 + C7A5x^1247 + C572x^1246 + 8588x^1245 + 2537x^1244 + 4BB5x^1243 + 4D2x^1242 + 805Ax^1241 + 51Ex^1240 + A0DAx^1239 + 8618x^1238 + B2CAx^1237 + 627Dx^1236 + 58DCx^1235 + 6D82x^1234 + 1C34x^1233 + 8749x^1232 + 12Ex^1231 + 3486x^1230 + E58Bx^1229 + 2CBDx^1228 + 2C05x^1227 + 8367x^1226 + E029x^1225 + 2AE5x^1224 + B7D9x^1223 + 9367x^1222 + 1ABFx^1221 + 82BDx^1220 + A42Ax^1219 + EABx^1218 + 36F6x^1217 + 75B7x^1216 + DA97x^1215 + 150Cx^1214 + 6674x^1213 + C94Ex^1212 + 802Cx^1211 + DAEx^1210 + 8CD0x^1209 + 2719x^1208 + D4E2x^1207 + D169x^1206 + 80D9x^1205 + C9AAx^1204 + CA3Ex^1203 + 6946x^1202 + D107x^1201 + CFA8x^1200 + B98Cx^1199 + 678Fx^1198 + 6544x^1197 + 9DF8x^1196 + D106x^1195 + 38E1x^1194 + 2083x^1193 + 42BCx^1192 + 6322x^1191 + 6035x^1190 + C055x^1189 + 2045x^1188 + A46Bx^1187 + FE6Cx^1186 + A2Fx^1185 + CEABx^1184 + 7C21x^1183 + 468Ex^1182 + 3CF5x^1181 + 99E4x^1180 + CEE7x^1179 + 5735x^1178 + 2B3Cx^1177 + A409x^1176 + 4EBx^1175 + 22F5x^1174 + 385Dx^1173 + 4AE1x^1172 + A1C2x^1171 + B9FDx^1170 + F785x^1169 + CEDx^1168 + 218Fx^1167 + 20E9x^1166 + 7541x^1165 + C38Dx^1164 + 1578x^1163 + B42Bx^1162 + 343Cx^1161 + A7F3x^1160 + 865Dx^1159 + 539Ax^1158 + 246Ax^1157 + 6921x^1156 + 6423x^1155 + 891Ax^1154 + E9D7x^1153 + 37Ex^1152 + AC40x^1151 + 127Ex^1150 + 3CEBx^1149 + D44Ax^1148 + E5A8x^1147 + 9E24x^1146 + ABAx^1145 + F4FBx^1144 + 5D4Cx^1143 + BEE9x^1142 + 293Ax^1141 + 572x^1140 + 9467x^1139 + 1130x^1138 + F005x^1137 + 62A5x^1136 + 440Bx^1135 + A0B2x^1134 + 6376x^1133 + 768Bx^1132 + 9CC2x^1131 + 20FCx^1130 + 2366x^1129 + 3302x^1128 + 87BBx^1127 + F812x^1126 + 91F7x^1125 + A925x^1124 + BE3Ax^1123 + 714Dx^1122 + DE7Ax^1121 + A832x^1120 + 7D5Fx^1119 + 2909x^1118 + AE61x^1117 + 4BEAx^1116 + 4E02x^1115 + DD42x^1114 + D9C9x^1113 + E73Cx^1112 + 7CC0x^1111 + C782x^1110 + 313Dx^1109 + 74B3x^1108 + C4EDx^1107 + 9F36x^1106 + 2076x^1105 + B98Ax^1104 + 319Ex^1103 + 5x^1102 + 4126x^1101 + E24Ex^1100 + EFE2x^1099 + 421Ex^1098 + 532Ex^1097 + EA48x^1096 + EA2Ex^1095 + F314x^1094 + 1C34x^1093 + 635Bx^1092 + 6995x^1091 + 4287x^1090 + BB0Fx^1089 + F47Cx^1088 + 6D9Cx^1087 + E0E7x^1086 + 876Dx^1085 + B0BCx^1084 + 4BD8x^1083 + 9C06x^1082 + 7D1Bx^1081 + 7235x^1080 + 8B1Cx^1079 + 5C88x^1078 + 9077x^1077 + F2A1x^1076 + C30Dx^1075 + 3C8Cx^1074 + 331Bx^1073 + 37AEx^1072 + 608Cx^1071 + B72Fx^1070 + F824x^1069 + C773x^1068 + AE48x^1067 + D3A3x^1066 + D42Fx^1065 + E562x^1064 + A7DDx^1063 + 8F9Dx^1062 + 19Fx^1061 + 2BF6x^1060 + ACEAx^1059 + 2103x^1058 + FE68x^1057 + 1787x^1056 + 4D3Ex^1055 + 959Dx^1054 + 2CD1x^1053 + 198Fx^1052 + A6DCx^1051 + 70D4x^1050 + 88F0x^1049 + 2231x^1048 + FA81x^1047 + 6192x^1046 + 2CC4x^1045 + ED09x^1044 + D3F9x^1043 + CF19x^1042 + A483x^1041 + 5B84x^1040 + FBE9x^1039 + 65C3x^1038 + 9D08x^1037 + 984x^1036 + F22Dx^1035 + 7D21x^1034 + 7834x^1033 + D9B9x^1032 + B9E7x^1031 + 6C58x^1030 + B60Bx^1029 + 4BC8x^1028 + CA4Cx^1027 + D11Dx^1026 + A9ADx^1025 + C001x^1024 + CEBDx^1023 + DC4Ex^1022 + 7FDx^1021 + 4E90x^1020 + 8C1Ax^1019 + 42C0x^1018 + B36Bx^1017 + CAAAx^1016 + D8A2x^1015 + 2F10x^1014 + C8DFx^1013 + ACE7x^1012 + 8FF9x^1011 + B8F6x^1010 + 5993x^1009 + E22Ax^1008 + 1AE5x^1007 + 3CB1x^1006 + E4A3x^1005 + 6E4x^1004 + 573Dx^1003 + 8EF9x^1002 + D62Bx^1001 + 3300x^1000 + 841Ex^999 + 9530x^998 + B385x^997 + 9AC2x^996 + 2D79x^995 + C899x^994 + F374x^993 + 63E6x^992 + 6257x^991 + 3170x^990 + 1908x^989 + E5E9x^988 + 86CFx^987 + 2DF5x^986 + 7084x^985 + 6073x^984 + 665Cx^983 + 2E99x^982 + 159Cx^981 + 6FE5x^980 + 3B6Cx^979 + 3602x^978 + F5x^977 + 8E9Ex^976 + 110Ex^975 + B113x^974 + 7ABFx^973 + 5273x^972 + 2EDDx^971 + BD6x^970 + 172Bx^969 + 30D4x^968 + 125Cx^967 + 856Cx^966 + FB6Ax^965 + DE82x^964 + 4B44x^963 + E33x^962 + 303Bx^961 + BB8Dx^960 + C1BAx^959 + BAB9x^958 + A430x^957 + 58C6x^956 + F909x^955 + 2441x^954 + 3D21x^953 + 5E08x^952 + 23BBx^951 + 649Cx^950 + BFEDx^949 + E220x^948 + F483x^947 + DD4Ex^946 + 60E1x^945 + 457x^944 + CC3Ex^943 + EDFDx^942 + 35E1x^941 + 86A6x^940 + F0F8x^939 + CD6x^938 + 6EFx^937 + 79A8x^936 + F2E1x^935 + D445x^934 + E09Ex^933 + CDB3x^932 + CC49x^931 + 1471x^930 + 99ACx^929 + D4C8x^928 + AAC0x^927 + 6B61x^926 + 7A46x^925 + DCC1x^924 + 346Fx^923 + 20C3x^922 + 1A27x^921 + FCEx^920 + D0C4x^919 + 9AABx^918 + 1054x^917 + 9C09x^916 + 1596x^915 + C42Fx^914 + 6139x^913 + 3055x^912 + 60DAx^911 + B7E3x^910 + CFAx^909 + 9AB0x^908 + 4CE9x^907 + 4F3Fx^906 + D96Fx^905 + 3B06x^904 + DB7Dx^903 + B405x^902 + C04Cx^901 + DE8Dx^900 + B963x^899 + E1C6x^898 + D9ABx^897 + 43D4x^896 + B065x^895 + 3C71x^894 + 594Dx^893 + 33C3x^892 + 4CE7x^891 + 8E32x^890 + 315Fx^889 + 72B6x^888 + 2CBx^887 + 5779x^886 + E176x^885 + C017x^884 + 7F5x^883 + 1BC1x^882 + BD80x^881 + B7B9x^880 + ADDCx^879 + DCBBx^878 + E444x^877 + BC1Cx^876 + 17C6x^875 + 977Ax^874 + A43Fx^873 + 931Dx^872 + BDB0x^871 + C4E5x^870 + BAFAx^869 + CDDAx^868 + 8978x^867 + 627Fx^866 + A0E0x^865 + 802Dx^864 + B385x^863 + 432Ax^862 + A39Ex^861 + C500x^860 + 96A3x^859 + A689x^858 + E8FBx^857 + 4735x^856 + D7F8x^855 + 8143x^854 + 387Bx^853 + 24AEx^852 + F063x^851 + 7484x^850 + E998x^849 + 961Ex^848 + A413x^847 + C395x^846 + A5A2x^845 + C9F0x^844 + BAA3x^843 + F041x^842 + B818x^841 + 7E0Dx^840 + 9AC3x^839 + 81CCx^838 + D65Dx^837 + 784Fx^836 + 3604x^835 + 390Fx^834 + 51B8x^833 + DAFCx^832 + 49E7x^831 + 245Dx^830 + 5A8Cx^829 + A378x^828 + BE4Dx^827 + C5A7x^826 + F100x^825 + 5AAx^824 + E86Bx^823 + CB5Fx^822 + 45A5x^821 + 5679x^820 + BC63x^819 + 638Dx^818 + 8D17x^817 + 7562x^816 + E61Ax^815 + EBE7x^814 + A7ECx^813 + 301Ex^812 + FA9Ax^811 + E4F2x^810 + 690Cx^809 + C02x^808 + D3A2x^807 + 22C8x^806 + DC7Ex^805 + C8EAx^804 + 8027x^803 + B27x^802 + 7F07x^801 + B2B6x^800 + EBCEx^799 + FA68x^798 + 9F8x^797 + 220x^796 + 5702x^795 + 99C1x^794 + 4740x^793 + EE96x^792 + 5D7Cx^791 + 98x^790 + D5C9x^789 + E8D6x^788 + AE17x^787 + 45E3x^786 + 9C67x^785 + B3F7x^784 + 232Ex^783 + B300x^782 + 6604x^781 + E078x^780 + BDD9x^779 + 7185x^778 + 7748x^777 + E536x^776 + C04Dx^775 + 61EBx^774 + AF59x^773 + 4BF7x^772 + C6E2x^771 + AADAx^770 + FB42x^769 + EF01x^768 + 827Bx^767 + 262Ex^766 + 1E31x^765 + C465x^764 + 204Bx^763 + 7279x^762 + A4F0x^761 + E439x^760 + D39Ax^759 + BEACx^758 + BDDBx^757 + 3BA4x^756 + E1EAx^755 + CD14x^754 + F9C3x^753 + A76Dx^752 + 23BDx^751 + 1E3Ex^750 + B893x^749 + BDB9x^748 + 229Ax^747 + 7D29x^746 + 2A86x^745 + C1FEx^744 + 3B53x^743 + 5A36x^742 + 54D6x^741 + 247Dx^740 + 28B5x^739 + 15EAx^738 + 7C86x^737 + 1E5Fx^736 + F9F3x^735 + 3D75x^734 + F338x^733 + 8C9Fx^732 + 9F15x^731 + 1C5Ax^730 + A70x^729 + 3165x^728 + DDA5x^727 + 85FBx^726 + 9DD3x^725 + 23BEx^724 + 9133x^723 + 84ADx^722 + 3F68x^721 + F6F0x^720 + A42Cx^719 + F0D2x^718 + 1D8x^717 + C220x^716 + 26EFx^715 + 1C75x^714 + 4D33x^713 + D19Ax^712 + FB6Ex^711 + 9E3Bx^710 + F3F3x^709 + C296x^708 + 6074x^707 + 328Ex^706 + 365Fx^705 + 9698x^704 + 30A7x^703 + 8BD6x^702 + 96CAx^701 + 352Ex^700 + E0B2x^699 + 38F3x^698 + 6B9Dx^697 + 34C5x^696 + A100x^695 + DB5Cx^694 + FBC9x^693 + CCCEx^692 + 70BAx^691 + B35Dx^690 + B056x^689 + ACC1x^688 + 656Ex^687 + 2C02x^686 + 1491x^685 + 9621x^684 + 424Ex^683 + A3B6x^682 + 85E5x^681 + A5Ex^680 + E450x^679 + E21Ax^678 + 17BCx^677 + B601x^676 + C26Ax^675 + F99Fx^674 + 6351x^673 + 1968x^672 + 98E3x^671 + 4052x^670 + A95x^669 + 378Ax^668 + C636x^667 + 4872x^666 + 167Dx^665 + 1FA8x^664 + E749x^663 + C515x^662 + DFBBx^661 + 8587x^660 + 14BFx^659 + A9B6x^658 + 7829x^657 + 6238x^656 + 2BACx^655 + CAA0x^654 + DF33x^653 + 8320x^652 + 546Ex^651 + 8671x^650 + 4F8Dx^649 + 2231x^648 + 267x^647 + F08Ax^646 + 6AAAx^645 + F9Cx^644 + 2D8Ex^643 + 2502x^642 + BB73x^641 + E019x^640 + 3545x^639 + DB5Ax^638 + A68Dx^637 + 95BBx^636 + 6195x^635 + 3476x^634 + EF64x^633 + 1105x^632 + 41BBx^631 + FC54x^630 + A327x^629 + A76x^628 + 6172x^627 + 4A41x^626 + F8F7x^625 + A1B9x^624 + ECF0x^623 + B2A1x^622 + 3D53x^621 + 7692x^620 + 177Cx^619 + 2567x^618 + C135x^617 + B74Bx^616 + 2D32x^615 + 248Bx^614 + 5D79x^613 + 3585x^612 + E4A2x^611 + 9E92x^610 + ADB0x^609 + B279x^608 + C020x^607 + 9ECx^606 + D34Ex^605 + E64Fx^604 + CBDAx^603 + 3803x^602 + 3F3Bx^601 + FB98x^600 + DCD1x^599 + ADC0x^598 + B100x^597 + EB25x^596 + A7C1x^595 + A478x^594 + 95EBx^593 + 6CB3x^592 + BBB8x^591 + 25BBx^590 + 3577x^589 + D77Ex^588 + 1E07x^587 + 8D7Cx^586 + 8B8Ex^585 + F2F0x^584 + 3E23x^583 + E080x^582 + 4B79x^581 + F73Ax^580 + 5D2Dx^579 + 31E9x^578 + 1E37x^577 + B748x^576 + 30FDx^575 + 4A48x^574 + C915x^573 + 3958x^572 + 953Fx^571 + 3D82x^570 + 91E3x^569 + 63EFx^568 + D108x^567 + CBF8x^566 + 5E04x^565 + 64A9x^564 + 8D68x^563 + CD37x^562 + 74ECx^561 + 4B89x^560 + 625Cx^559 + 5081x^558 + 69D3x^557 + ADDCx^556 + 354Ax^555 + 1B3Cx^554 + 47C0x^553 + E93x^552 + 5F45x^551 + B3E0x^550 + E277x^549 + A460x^548 + 1BCCx^547 + 32F4x^546 + 5706x^545 + 6ECAx^544 + A7B7x^543 + 7E12x^542 + 2B3Ex^541 + A970x^540 + 5D80x^539 + 5D60x^538 + FA9Ax^537 + 89CEx^536 + 2082x^535 + A5E3x^534 + 6BEBx^533 + 7000x^532 + 6253x^531 + 1EC5x^530 + 3E09x^529 + 52E4x^528 + 938Ex^527 + 66CEx^526 + E32Bx^525 + 4ACBx^524 + DA67x^523 + FFDFx^522 + A14Fx^521 + 11FDx^520 + D540x^519 + 67B7x^518 + 2AF5x^517 + A958x^516 + 7CD0x^515 + 9803x^514 + A444x^513 + F409x^512 + 3907x^511 + 8FF5x^510 + D4C7x^509 + 5B83x^508 + B54Dx^507 + 254Ax^506 + 2630x^505 + A83Dx^504 + D153x^503 + 8321x^502 + AAFDx^501 + C82x^500 + 4130x^499 + CBC9x^498 + A0FDx^497 + 69E1x^496 + 191Cx^495 + B8A1x^494 + 5F84x^493 + 974Fx^492 + C084x^491 + 5E90x^490 + 4E96x^489 + F538x^488 + D4E9x^487 + 7600x^486 + F6D4x^485 + C173x^484 + 812Dx^483 + A792x^482 + A8C4x^481 + 110Cx^480 + 7E7Bx^479 + 3CF9x^478 + FE09x^477 + D755x^476 + 2B0Bx^475 + 31C9x^474 + A95Bx^473 + CBCBx^472 + 9332x^471 + BD97x^470 + C3F1x^469 + 5E3Fx^468 + 50C5x^467 + 3BE0x^466 + D45Cx^465 + 1263x^464 + 7770x^463 + AF7x^462 + 2869x^461 + B810x^460 + 292Fx^459 + 8822x^458 + 8CD1x^457 + 7D3Fx^456 + 3356x^455 + A02Fx^454 + 6E84x^453 + 78CFx^452 + 532Ex^451 + F61Cx^450 + 9857x^449 + 4BBCx^448 + 1CDx^447 + AE4Bx^446 + 2E7Cx^445 + CA75x^444 + F05x^443 + DC8Bx^442 + 91EFx^441 + AB98x^440 + DF31x^439 + BBD5x^438 + 453Cx^437 + 69DBx^436 + 1FEEx^435 + 7992x^434 + A46Ex^433 + 57EBx^432 + F358x^431 + D118x^430 + F7C3x^429 + 1E19x^428 + DC12x^427 + 6829x^426 + F5E9x^425 + DA76x^424 + C42Fx^423 + B8FBx^422 + 8501x^421 + 11Fx^420 + 5204x^419 + F2FBx^418 + FBB0x^417 + 2126x^416 + 92D7x^415 + 26A1x^414 + 41B5x^413 + 73E6x^412 + 92CCx^411 + 32Ax^410 + 4201x^409 + 33A2x^408 + 507Ex^407 + DF39x^406 + 6923x^405 + 7A67x^404 + 35D4x^403 + 3293x^402 + F7DFx^401 + 2476x^400 + 9C1Ax^399 + 5978x^398 + B7B8x^397 + E5A6x^396 + 244Bx^395 + EABEx^394 + C112x^393 + E3A4x^392 + 3100x^391 + 8845x^390 + 96F2x^389 + 11B0x^388 + 29C7x^387 + 5CEx^386 + C8Fx^385 + C4BFx^384 + 33E7x^383 + 5D3Cx^382 + A7F3x^381 + CF6Ex^380 + 82CEx^379 + A675x^378 + 10BEx^377 + 1A01x^376 + D612x^375 + 89DCx^374 + AB69x^373 + B82Fx^372 + 8EE0x^371 + B829x^370 + 29D4x^369 + 847Cx^368 + 22C5x^367 + 2EB9x^366 + 692Ex^365 + A600x^364 + 5E0Ex^363 + 8CD3x^362 + 62D5x^361 + 47ECx^360 + 8362x^359 + EB50x^358 + 7517x^357 + B4D2x^356 + D20Bx^355 + DE92x^354 + B7A6x^353 + BF3Bx^352 + 81C1x^351 + A3Ax^350 + 671Dx^349 + 6FE6x^348 + D398x^347 + FEBCx^346 + 5EA5x^345 + 5700x^344 + 5C7Fx^343 + 91E4x^342 + DEFDx^341 + AFDBx^340 + 14A0x^339 + F83Ex^338 + CD13x^337 + 314Cx^336 + 6E6Dx^335 + 2806x^334 + 1E7Ex^333 + C09Fx^332 + C671x^331 + C30Ex^330 + A53Cx^329 + C426x^328 + DFF5x^327 + 8D5x^326 + 500Ax^325 + 21A3x^324 + CA11x^323 + 4832x^322 + CE06x^321 + 5010x^320 + 74F6x^319 + FB8Fx^318 + 6ED6x^317 + 72A0x^316 + 5A5Ex^315 + D361x^314 + 5E1Dx^313 + 88C0x^312 + 4D5Ex^311 + 63FEx^310 + 2930x^309 + 41F9x^308 + F3B9x^307 + F192x^306 + F3A1x^305 + 94BBx^304 + 6850x^303 + 23BCx^302 + EE4Ax^301 + C1F9x^300 + 2FEBx^299 + 7A9Bx^298 + 2870x^297 + 657Ex^296 + F2C7x^295 + 4CCEx^294 + EE0Cx^293 + 7313x^292 + 969Bx^291 + E3BBx^290 + 3440x^289 + 8390x^288 + D988x^287 + 201Fx^286 + D42Cx^285 + 32BDx^284 + F9AAx^283 + A30x^282 + 7E22x^281 + 732x^280 + 10Ex^279 + 8346x^278 + 3192x^277 + 3EA6x^276 + 4872x^275 + 19D8x^274 + F44Ex^273 + 82D2x^272 + 1B32x^271 + 585Ax^270 + 48CCx^269 + A002x^268 + 744Ax^267 + 2AC7x^266 + 4403x^265 + 324x^264 + BCEDx^263 + EC82x^262 + 399x^261 + 95B3x^260 + DBA0x^259 + C017x^258 + 9D7Bx^257 + F00x^256 + 72E9x^255 + 3566x^254 + FAC8x^253 + C787x^252 + FD7Dx^251 + 7C8Bx^250 + 9320x^249 + 3909x^248 + B65x^247 + 5A37x^246 + ABEFx^245 + E60Fx^244 + 152Ex^243 + 9243x^242 + F54Cx^241 + 6C9Ex^240 + AC68x^239 + 8653x^238 + 72Dx^237 + B358x^236 + 9FA7x^235 + F11Ax^234 + D906x^233 + FD1Ax^232 + 40DEx^231 + B8ECx^230 + 4EEx^229 + 5AA5x^228 + 50BDx^227 + 9B74x^226 + A35x^225 + 5E86x^224 + 823x^223 + A1FDx^222 + E14Bx^221 + 741Ax^220 + 1460x^219 + A0FAx^218 + DA02x^217 + A1E8x^216 + 8472x^215 + 7ED0x^214 + AF81x^213 + 48DBx^212 + 1EC8x^211 + 5B05x^210 + A9AFx^209 + 27C7x^208 + 8BBx^207 + 1682x^206 + 4828x^205 + 16EBx^204 + CF87x^203 + 6DE0x^202 + E1D1x^201 + 7E6Cx^200 + 30BFx^199 + 9A4x^198 + BADEx^197 + 592x^196 + 62F7x^195 + 8F7x^194 + E470x^193 + 95AAx^192 + 6334x^191 + 72x^190 + 634Ax^189 + 99C4x^188 + 6325x^187 + 5211x^186 + 9C0x^185 + 8E19x^184 + CEFCx^183 + 696Cx^182 + 4415x^181 + 29A3x^180 + 25B0x^179 + 6EB7x^178 + 76B7x^177 + FE6Fx^176 + 8909x^175 + 8A32x^174 + D7Ex^173 + 3553x^172 + D04Fx^171 + A7C7x^170 + 7A9Ax^169 + BD83x^168 + 2C75x^167 + ACC5x^166 + 8612x^165 + BBA1x^164 + E9FEx^163 + 8425x^162 + CB5Bx^161 + B9C3x^160 + C789x^159 + 2577x^158 + 444Fx^157 + 84C0x^156 + 17F6x^155 + B4A1x^154 + F4D6x^153 + 2B85x^152 + EDEx^151 + 8E03x^150 + 9AB7x^149 + 8AD2x^148 + 671Fx^147 + C943x^146 + EC7Fx^145 + 6F97x^144 + A98Dx^143 + 83A0x^142 + 6012x^141 + 99C7x^140 + F3E5x^139 + 458Ax^138 + 706Ax^137 + 7708x^136 + F014x^135 + BA12x^134 + E07Cx^133 + B05Cx^132 + AE1Fx^131 + 1B4Cx^130 + E69x^129 + 7FFEx^128 + B47x^127 + CAA2x^126 + E8Ex^125 + D1FFx^124 + 8277x^123 + FA0Fx^122 + E380x^121 + 95BCx^120 + 95BCx^119 + C97Ex^118 + 9107x^117 + FEBBx^116 + 6364x^115 + 61C9x^114 + 33x^113 + C13Bx^112 + 83E9x^111 + 71D7x^110 + 621Fx^109 + F4DCx^108 + 667Bx^107 + 5CE5x^106 + CC36x^105 + 19D2x^104 + 9771x^103 + 1ACx^102 + 3044x^101 + 430x^100 + 6272x^99 + 7220x^98 + E5Fx^97 + FBD5x^96 + 876Dx^95 + CAE9x^94 + A6C3x^93 + 56Dx^92 + FD2Dx^91 + 3095x^90 + 3A10x^89 + BD85x^88 + AD8Bx^87 + F669x^86 + 2C58x^85 + 8124x^84 + 4363x^83 + E208x^82 + 1B2Ex^81 + C52Cx^80 + 1E5x^79 + F6B4x^78 + 7D11x^77 + 97F3x^76 + A154x^75 + B33Fx^74 + C310x^73 + CA86x^72 + DBE4x^71 + F92Ax^70 + D961x^69 + 5F3Ex^68 + CC9Ex^67 + 9719x^66 + 6984x^65 + B7Bx^64 + 90DFx^63 + C110x^62 + B2BBx^61 + 9ED5x^60 + 1145x^59 + A7C2x^58 + 3812x^57 + 498Ax^56 + 7B9x^55 + 29D4x^54 + 761Dx^53 + 1E61x^52 + 756Cx^51 + 5FCx^50 + 2BB1x^49 + F3DCx^48 + 80F8x^47 + A42Cx^46 + 3197x^45 + 349Bx^44 + BD00x^43 + 6198x^42 + 5CAFx^41 + CD1Cx^40 + 6987x^39 + 5CE6x^38 + 7865x^37 + F047x^36 + 31E8x^35 + B4F6x^34 + 337Dx^33 + 91DBx^32 + 6C54x^31 + 9C66x^30 + 9BA8x^29 + 8D31x^28 + D4BAx^27 + A0B0x^26 + 4F09x^25 + ADF7x^24 + D46Bx^23 + DDCBx^22 + C4DAx^21 + F410x^20 + 84F4x^19 + 94B7x^18 + 37D7x^17 + F278x^16 + EC4Bx^15 + 1F56x^14 + C899x^13 + B186x^12 + E971x^11 + 9F3Fx^10 + 7D63x^9 + EB0Ax^8 + 7348x^7 + 876Ax^6 + B96Dx^5 + 40E8x^4 + 520x^3 + 2A76x^2 + 2FBBx^1 + FEC1'\n",
            "try 1\n",
            "<Pyfhel ERROR> encoding type mistmatch in add terms\n",
            "try 2\n",
            "'int' object is not iterable\n",
            "try 3\n",
            "success!!\n",
            "decoded and decrypted:  [3, 4, 5, 6, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dGgthRc7sLBx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "HE = Pyfhel()           \n",
        "HE.contextGen( p=65537, flagBatching=True )  \n",
        "HE.keyGen()   \n",
        "# need to get data into the correct shape\n",
        "x_test = x_test.reshape( (x_test.shape[ 0 ], -1 ) )\n",
        "\n",
        "slots = HE.getnSlots()\n",
        "num_features = x_test.shape[ 1 ]\n",
        "\n",
        "print( x_test.shape )\n",
        "\n",
        "# encrypt values\n",
        "# iterate over every feature\n",
        "cipher_texts = []\n",
        "\n",
        "\n",
        "# encode weights\n",
        "\n",
        "\n",
        "start = time.time()\n",
        "\n",
        "# perform prediction\n",
        "\n",
        "# decrypt results\n",
        "print( 'prediction took:', time.time() - start )\n",
        "result = HE.decryptBatch( prediction )\n",
        "print( result )\n",
        "print( len(result) )\n",
        "\n",
        "\n",
        "print( percp.decision_function( x_test ) )\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A3Ek20_PMreG",
        "colab_type": "text"
      },
      "source": [
        "Why did that not work?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c2CKNn5pMsJ5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# change the weights to be smaller\n",
        "\n",
        "# create a copy of the preceptron\n",
        "percp1 = Perceptron(fit_intercept=False)\n",
        "percp1.classes_ = percp.classes_ \n",
        "coef = np.copy( percp.coef_ )\n",
        "\n",
        "# make changes to the coefficents\n",
        "\n",
        "percp1.coef_ = coef\n",
        "percp1.intercept_ = percp.intercept_\n",
        "\n",
        "print( 'test score: ', percp1.score( x_test.reshape( ( x_train.shape[ 0 ], -1 ) ), y_test ) )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oOA-iWwWYWOT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "HE = Pyfhel()           \n",
        "HE.contextGen( p=65537, flagBatching=True )  \n",
        "HE.keyGen()   \n",
        "# need to get data into the correct shape\n",
        "x_test = x_test.reshape( (x_test.shape[ 0 ], -1 ) )\n",
        "\n",
        "slots = HE.getnSlots()\n",
        "num_features = x_test.shape[ 1 ]\n",
        "\n",
        "print( x_test.shape )\n",
        "\n",
        "# encrypt values\n",
        "# iterate over every feature\n",
        "cipher_texts = []\n",
        "\n",
        "\n",
        "# encode weights\n",
        "\n",
        "\n",
        "start = time.time()\n",
        "\n",
        "# perform prediction\n",
        "\n",
        "# decrypt results\n",
        "print( 'prediction took:', time.time() - start )\n",
        "result = HE.decryptBatch( prediction )\n",
        "print( result )\n",
        "print( len(result) )\n",
        "\n",
        "\n",
        "print( percp1.decision_function( x_test ) )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZkuNVOUWLa9n",
        "colab_type": "text"
      },
      "source": [
        "putting together the building blocks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vgjJsD3BCHnw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train = x_train.reshape( ( x_train.shape[ 0 ], -1 ) )\n",
        "x_test = x_test.reshape( ( x_test.shape[ 0 ], -1 ) )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HZGxY-t5LekJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "\n",
        "\n",
        "print( x_train.shape )\n",
        "\n",
        "model = Sequential()\n",
        "model.add( Dense( 2, activation='relu', input_shape=x_train.shape[ 1: ]  ) )\n",
        "model.add( Dense( 1, activation='sigmoid' ) )\n",
        "\n",
        "\n",
        "model.summary()\n",
        "model.compile(loss='mean_squared_error',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit( x_train, y_train, epochs=32, verbose=1 )\n",
        "model.evaluate( x_test, y_test )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S_Ye34djOwUU",
        "colab_type": "text"
      },
      "source": [
        "lets build a model that can work with HE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "NCDYnUM7yVof",
        "colab": {}
      },
      "source": [
        "def relu_aprox( x ):\n",
        "  return 0.046875*x**2 + 0.5*x + 0.9375\n",
        "\n",
        "def sig_aprox( x ):\n",
        "   return 0.424413181578472*x**2 + 0.500000000000002*x + 0.106103295394586\n",
        "\n",
        "x_train = x_train.astype( float ) / 255.\n",
        "x_test = x_test.astype( float ) / 255.\n",
        "\n",
        "\n",
        "model = Sequential()\n",
        "model.add( Dense( 2 , activation=relu_aprox, input_shape=x_train.shape[ 1: ]  ) )\n",
        "model.add( Dense( 1, activation='sigmoid' ) )\n",
        "\n",
        "model.summary()\n",
        "model.compile(loss='mean_squared_error',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit( x_train, y_train, epochs=32 )\n",
        "\n",
        "print( 'keras' )\n",
        "print( model.evaluate( x_test, y_test ) )\n",
        "print( 'prediction' )\n",
        "test_sample = x_test[ 0:1 ]\n",
        "print( 'prediction', model.predict( test_sample ) )\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rhmf9IJ9yy88",
        "colab_type": "text"
      },
      "source": [
        "Extract weights and setup the encryption scheme\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TChntqNrytDy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#-------------------------------------------------------------------------------\n",
        "# setup HE\n",
        "#-------------------------------------------------------------------------------\n",
        "print('HE')\n",
        "HE = Pyfhel()           \n",
        "HE.contextGen(p=65537, m=4096)  \n",
        "# generate keys\n",
        "HE.keyGen()    \n",
        "\n",
        "# extract weights\n",
        "print( 'weights layer 0' )\n",
        "layer0_weights = model.layers[ 0 ].get_weights() # format [ weights, biases ]\n",
        "print( layer0_weights[ 0 ].shape, layer0_weights[ 1 ].shape )\n",
        "\n",
        "print( 'weights layer 1' )\n",
        "layer1_weights = model.layers[ 1 ].get_weights()\n",
        "print( layer1_weights[ 0 ].shape, layer1_weights[ 1 ].shape )\n",
        "\n",
        "\n",
        "\n",
        "# let's implement the actual layers\n",
        "#-------------------------------------------------------------------------------\n",
        "# layers\n",
        "#-------------------------------------------------------------------------------\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "efLrqhtf014Z",
        "colab_type": "text"
      },
      "source": [
        "Convert values and encrypt"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tFDaCtA304O_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#-------------------------------------------------------------------------------\n",
        "# convert values\n",
        "#-------------------------------------------------------------------------------\n",
        "\n",
        "def weight_converter( weights, biases ):\n",
        "  bias_ = []     # holds converted biases \n",
        "  weights_ = []  # holds converted weights \n",
        "\n",
        "  # convert biases \n",
        "  for b in biases:\n",
        "    bias_.append( HE.encodeFrac( b ) )\n",
        "\n",
        "  # convert weights\n",
        "  for input in weights:\n",
        "    w = []\n",
        "    for weight in input:\n",
        "      w.append( HE.encodeFrac( weight ) )\n",
        "      weights_.append( w )  \n",
        "  \n",
        "  return weights_, bias_\n",
        "\n",
        "# layer 0\n",
        "weights_0, bias_0 = weight_converter( layer0_weights[ 0 ], layer0_weights[ 1 ] )\n",
        "# layer 1\n",
        "weights_1, bias_1 = weight_converter( layer1_weights[ 0 ], layer1_weights[ 1 ] )\n",
        "\n",
        "\n",
        "# convert values for activation functions\n",
        "relu_aprox_coef = [ HE.encodeFrac( 0.046875 ),  HE.encodeFrac( 0.5 ), \n",
        "              HE.encodeFrac( 0.9375 ) ]\n",
        "\n",
        "sig_aprox_coef = [ HE.encodeFrac( 0.424413181578472 ),\n",
        "                  HE.encodeFrac( 0.500000000000002 ),\n",
        "                  HE.encodeFrac( 0.106103295394586 ) ]\n",
        "\n",
        "#-------------------------------------------------------------------------------\n",
        "# encrypt inputs\n",
        "#-------------------------------------------------------------------------------\n",
        "inputs = [ HE.encryptFrac( x ) for x in test_sample[ 0 ] ]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zjw9vG2i1F9z",
        "colab_type": "text"
      },
      "source": [
        "Now it is your turn. Implement the layers. Good Luck :D"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mDTnZE091UvP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}